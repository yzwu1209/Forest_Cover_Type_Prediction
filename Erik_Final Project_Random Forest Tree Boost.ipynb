{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest, Decision Tree and Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook for testing random forest, decison tree and neural network on the dataset we are given for the W207 final project. Currently only random forest and decision tree are included. Will work on Nerual Network in the week of 7/15.\n",
    "\n",
    "In addition, this notebook included some additional notes on classifying the dataset using multinomial naive bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the packages needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data, shuffle and split it into training and testing sets in 70%, 30% split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('forest-cover-type-prediction/train.csv', 'rt') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = np.genfromtxt('forest-cover-type-prediction/train.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = my_data[1:, 1:my_data.shape[1]-1]  # avoid getting headers and ID column\n",
    "labels = my_data[1:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the training data\n",
    "np.random.seed(0)\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(data.shape[0]))\n",
    "\n",
    "shuffled_data = data[shuffle]\n",
    "shuffled_labels = labels[shuffle]\n",
    "shuffled_labels = shuffled_labels - 1\n",
    "\n",
    "# split the data to 60% train, 20% dev and 20% test\n",
    "num_train = int(shuffled_data.shape[0]*0.6)\n",
    "num_dev = int(shuffled_data.shape[0]*0.8)\n",
    "\n",
    "train_data, train_labels = shuffled_data[:num_train], shuffled_labels[:num_train]\n",
    "dev_data, dev_labels = shuffled_data[num_train:num_dev], shuffled_labels[num_train:num_dev]\n",
    "test_data, test_labels = shuffled_data[num_dev:], shuffled_labels[num_dev:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest, Decision Tree and Adaboost\n",
    "\n",
    "Without any feature engineering and optimization, use the above three classifier on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (a decision tree): 0.7751322751322751\n",
      "Accuracy (a random forest): 0.8465608465608465\n",
      "Accuracy (adaboost with decision trees): 0.41898148148148145\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion=\"entropy\", splitter=\"best\", random_state=0)\n",
    "dt.fit(train_data, train_labels)\n",
    "\n",
    "print('Accuracy (a decision tree):', dt.score(dev_data, dev_labels))\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(train_data, train_labels)\n",
    "\n",
    "print('Accuracy (a random forest):', rfc.score(dev_data, dev_labels))\n",
    "\n",
    "abc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, learning_rate=0.1)\n",
    "\n",
    "abc.fit(train_data, train_labels)\n",
    "print('Accuracy (adaboost with decision trees):', abc.score(dev_data, dev_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the box, random forest seems to have really good accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
